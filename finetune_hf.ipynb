{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Following https://github.com/bigcode-project/starcoder"
      ],
      "metadata": {
        "id": "FENgUg9ixK5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqZeZlz6KGgB"
      },
      "outputs": [],
      "source": [
        "# Step 1: Clone the repo and setup environment\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "repo_dir = \"/content/tamarind-finetune\"\n",
        "repo_url = \"https://github.com/smartrics/tamarind-finetune.git\"\n",
        "\n",
        "if os.path.isdir(repo_dir):\n",
        "    print(\"Directory 'tamarind-finetune' exists. Pulling latest changes...\")\n",
        "    subprocess.run([\"git\", \"-C\", repo_dir, \"pull\"], check=True)\n",
        "else:\n",
        "    print(\"Directory 'tamarind-finetune' does not exist. Cloning repository...\")\n",
        "    subprocess.run([\"git\", \"clone\", repo_url, repo_dir], check=True)\n",
        "print(\"finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC1HVjTjKGgC"
      },
      "outputs": [],
      "source": [
        "%cd /content/tamarind-finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weâ€™ll finetune `bigcode/starcoderbase-1b`, which is a 1B parameter model trained on 80+ programming languages. This is a gated model, so if you plan to run this notebook with this exact model, youâ€™ll need to gain access to it on the modelâ€™s page. Log in to your Hugging Face account to do so:"
      ],
      "metadata": {
        "id": "MpJEMYoMxcxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIrUJnP5KGgC"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install transformers\n",
        "!pip install git+https://github.com/huggingface/peft.git\n",
        "!pip install datasets accelerate huggingface_hub bitsandbytes wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# --- 2. Login to Hugging Face Hub ---\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "YY9BwThwxU7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "6Ig-HkRGmSlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_starcoderbase/finetune.py \\\n",
        "  --model_path=\"bigcode/starcoderbase-1b\"\\\n",
        "  --dataset_path=\"./data_starcoderbase/tamarind_data.csv\" \\\n",
        "  --subset=\"data/finetune\"\\\n",
        "  --split=\"train\"\\\n",
        "  --size_valid_set 10000\\\n",
        "  --seq_length 8192\\\n",
        "  --max_steps 1000\\\n",
        "  --batch_size 1\\\n",
        "  --input_column_name=\"question\"\\\n",
        "  --output_column_name=\"response\"\\\n",
        "  --gradient_accumulation_steps 16\\\n",
        "  --learning_rate 1e-4\\\n",
        "  --lr_scheduler_type=\"cosine\"\\\n",
        "  --num_warmup_steps 100\\\n",
        "  --weight_decay 0.05\\\n",
        "  --output_dir=\"./checkpoints\""
      ],
      "metadata": {
        "id": "PEGTVU9ymetJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The size of the SE dataset is better manageable when using streaming. We also have to precise the split of the dataset that is used. For more details, check the dataset's page on ðŸ¤—. Similarly we can modify the command to account for the availability of GPUs"
      ],
      "metadata": {
        "id": "XGOo3Ftf4LBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_starcoderbase/merge_peft_adapters.py \\\n",
        "   --base_model_name_or_path \"bigcode/starcoderbase-1b\" \\\n",
        "   --peft_model_path \"./checkpoints/checkpoint-100\" \\\n",
        "   --merged_model_name_or_path \"smartrics/starcoderbase-1b-tamarind\" \\\n",
        "   --push_to_hub"
      ],
      "metadata": {
        "id": "diAEUNB043nZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}